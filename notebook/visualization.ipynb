{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset, Box, Quaternion, view_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup the path of LyftDataset and csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 11.6 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.6 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "lyft_dataset_root = \"/media/jd/data2/DataSet/Lyft/LyftDataSet\"\n",
    "df = pd.read_csv('../visualization.csv')\n",
    "lyft = LyftDataset(data_path=lyft_dataset_root, json_path=os.path.join(lyft_dataset_root, 'train_data'), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get2Box(boxes_list, names_list, token, scores=None):\n",
    "    '''Given a list of boxes in `x,y,z,w,l,h,yaw` format, returns them in `Box` format\n",
    "    \n",
    "    Args:\n",
    "    boxes_list: a list of boxes in [x, y, z, w, l, h, yaw] format\n",
    "    names_list: classes the boxes belong to\n",
    "    token: token of the sample the boxes belong to\n",
    "    scores: predicted confidence scores, only for predicted boxes, \n",
    "    '''\n",
    "    boxes = []\n",
    "    for idx in range(len(boxes_list)):\n",
    "        center = boxes_list[idx, :3] # x, y, z\n",
    "        yaw = boxes_list[idx, 6]\n",
    "        size = boxes_list[idx, 3:6] # w, l, h\n",
    "        name = names_list[idx]\n",
    "        detection_score = 1.0 # for ground truths \n",
    "        if scores is not None:\n",
    "            detection_score = scores[idx]\n",
    "        quat = Quaternion(axis=[0, 0, 1], radians=yaw)\n",
    "        box = Box(\n",
    "            center=center,\n",
    "            size=size,\n",
    "            orientation=quat,\n",
    "            score=detection_score,\n",
    "            name=name,\n",
    "            token=token\n",
    "        )\n",
    "        boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "def get_pred_gt(pred_df, idx): \n",
    "    '''Given an index `idx`, this function reads ground truth and predicted strings and returns\n",
    "    corresponding boxes in `Box` format'''\n",
    "    \n",
    "    sample_token = pred_df.iloc[idx]['Id']\n",
    "    \n",
    "    string = pred_df.iloc[idx]['GroundTruthString'].split()\n",
    "    gt_objects = [string[x:x+8] for x in range(0, len(string), 8)]\n",
    "    string = pred_df.iloc[idx]['PredictionString'].split()\n",
    "    pred_objects = [string[x:x+9] for x in range(0, len(string), 9)]\n",
    "    \n",
    "    # str -> float, in x,y,z,w,l,h,yaw format\n",
    "    gt_boxes = np.array([list(map(float, x[0:7])) for x in gt_objects])\n",
    "    gt_class = np.array([x[7] for x in gt_objects])\n",
    "    pred_scores = np.array([float(x[0]) for x in pred_objects])\n",
    "    pred_boxes = np.array([list(map(float, x[1:8])) for x in pred_objects])\n",
    "    pred_class = np.array([x[8] for x in pred_objects])\n",
    "    \n",
    "    # x,y,z,w,l,h,yaw -> Box instance\n",
    "    predBoxes = get2Box(pred_boxes, pred_class, sample_token, scores=pred_scores)\n",
    "    gtBoxes = get2Box(gt_boxes, gt_class, sample_token)\n",
    "    \n",
    "    return predBoxes, gtBoxes \n",
    "\n",
    "def glb_to_sensor(box, sample_data):\n",
    "    '''Get a box from global frame to sensor's frame of reference '''\n",
    "    box = box.copy() # v.imp\n",
    "    cs_record = lyft.get('calibrated_sensor', sample_data['calibrated_sensor_token'])\n",
    "    pose_record = lyft.get('ego_pose', sample_data['ego_pose_token'])\n",
    "    \n",
    "    # global to ego \n",
    "    box.translate(-np.array(pose_record['translation']))\n",
    "    box.rotate_around_origin(Quaternion(pose_record['rotation']).inverse)\n",
    "    # ego to sensor\n",
    "    box.translate(-np.array(cs_record['translation']))\n",
    "    box.rotate_around_origin(Quaternion(cs_record['rotation']).inverse)\n",
    "    return box\n",
    "\n",
    "def get_lines(boxes, name):\n",
    "    '''Takes in boxes, extracts edges and returns `go.Scatter3d` object for those lines'''\n",
    "    x_lines = []\n",
    "    y_lines = []\n",
    "    z_lines = []\n",
    "\n",
    "    def f_lines_add_nones():\n",
    "        x_lines.append(None)\n",
    "        y_lines.append(None)\n",
    "        z_lines.append(None)\n",
    "\n",
    "    ixs_box_0 = [0, 1, 2, 3, 0]\n",
    "    ixs_box_1 = [4, 5, 6, 7, 4]\n",
    "\n",
    "    for box in boxes:\n",
    "        box = glb_to_sensor(box, sample_data)\n",
    "        points = view_points(box.corners(), view=np.eye(3), normalize=False)\n",
    "        x_lines.extend(points[0, ixs_box_0])\n",
    "        y_lines.extend(points[1, ixs_box_0])\n",
    "        z_lines.extend(points[2, ixs_box_0])\n",
    "        f_lines_add_nones()\n",
    "        x_lines.extend(points[0, ixs_box_1])\n",
    "        y_lines.extend(points[1, ixs_box_1])\n",
    "        z_lines.extend(points[2, ixs_box_1])\n",
    "        f_lines_add_nones()\n",
    "        for i in range(4):\n",
    "            x_lines.extend(points[0, [ixs_box_0[i], ixs_box_1[i]]])\n",
    "            y_lines.extend(points[1, [ixs_box_0[i], ixs_box_1[i]]])\n",
    "            z_lines.extend(points[2, [ixs_box_0[i], ixs_box_1[i]]])\n",
    "            f_lines_add_nones()\n",
    "\n",
    "    lines = go.Scatter3d(x=x_lines, y=y_lines, z=z_lines, mode=\"lines\", name=name)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read pred & gt boxes from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted and ground boxes for each sample in `Box` format\n",
    "pred_boxes = []\n",
    "gt_boxes = []\n",
    "for idx in range(len(df)):\n",
    "    pBoxes, gBoxes = get_pred_gt(df, idx)\n",
    "    pred_boxes.append(pBoxes)\n",
    "    gt_boxes.append(gBoxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization pred & gt on bev image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 # change this to visualize other samples\n",
    "\n",
    "sample_token = df.iloc[idx]['Id']\n",
    "\n",
    "sample = lyft.get('sample', sample_token)\n",
    "sample_data = lyft.get('sample_data', sample['data']['LIDAR_TOP'])\n",
    "path = sample_data['filename']\n",
    "path = os.path.join(lyft_dataset_root, path)\n",
    "lidar_points = np.fromfile(path, dtype=np.float32, count=-1).reshape([-1, 5])[:, :4]\n",
    "\n",
    "_, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "# create colors based on the distance of the point from lidar\n",
    "axes_limit=60\n",
    "\n",
    "dists = np.sqrt(np.sum(lidar_points[:, :2] ** 2, axis=1))\n",
    "colors = np.minimum(1, dists / axes_limit / np.sqrt(2))\n",
    "ax.scatter(lidar_points[:, 0], lidar_points[:, 1], c=colors, s=0.2)\n",
    "ax.plot(0, 0, \"x\", color=\"red\") # plot lidar location\n",
    "\n",
    "# Limit visible range.\n",
    "ax.set_xlim(-axes_limit, axes_limit)\n",
    "ax.set_ylim(-axes_limit, axes_limit)\n",
    "\n",
    "# plot the ground truths\n",
    "for box in gt_boxes[idx]:\n",
    "    box = glb_to_sensor(box, sample_data)\n",
    "    c = np.array([255, 158, 0 ]) / 255.0 # Orange\n",
    "    box.render(ax, view=np.eye(4), colors=(c, c, c))\n",
    "\n",
    "# plot the predicted boxes\n",
    "for box in pred_boxes[idx]:\n",
    "    box = glb_to_sensor(box, sample_data)\n",
    "    c = np.array([0, 0, 230]) / 255.0 # Blue\n",
    "    box.render(ax, view=np.eye(4), colors=(c, c, c))\n",
    "\n",
    "# gotta invert for consistency with lyft's inbuilt plots\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().invert_xaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization pred & gt  in 3D pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0 # change this to visualize other samples\n",
    "sample_token = df.iloc[idx]['Id']\n",
    "\n",
    "sample = lyft.get(\"sample\", sample_token)\n",
    "sample_data = lyft.get(\"sample_data\", sample[\"data\"][\"LIDAR_TOP\"])\n",
    "path = sample_data['filename']\n",
    "\n",
    "path = os.path.join(lyft_dataset_root, path)\n",
    "lidar_points = np.fromfile(path, dtype=np.float32, count=-1).reshape([-1, 5])[:, :4]\n",
    "\n",
    "# plot the points\n",
    "df_tmp = pd.DataFrame(lidar_points[:, :3], columns=[\"x\", \"y\", \"z\"])\n",
    "df_tmp[\"norm\"] = np.sqrt(np.power(df_tmp[[\"x\", \"y\", \"z\"]].values, 2).sum(axis=1))\n",
    "scatter = go.Scatter3d(\n",
    "    x=df_tmp[\"x\"],\n",
    "    y=df_tmp[\"y\"],\n",
    "    z=df_tmp[\"z\"],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(size=1, color=df_tmp[\"norm\"], opacity=0.8),\n",
    ")\n",
    "\n",
    "gt_lines = get_lines(gt_boxes[idx], 'gt_boxes')\n",
    "pred_lines = get_lines(pred_boxes[idx], 'pred_boxes')\n",
    "fig = go.Figure(data=[scatter, gt_lines, pred_lines])\n",
    "fig.update_layout(scene_aspectmode=\"data\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
